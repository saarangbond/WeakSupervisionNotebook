{
  "metadata": {
    "kernelspec": {
      "display_name": "Pyolite",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "%matplotlib inline\nimport json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\ndataset_path = './data'\nanns_file_path = dataset_path + '/' + 'annotations.json'\n\n# Read annotations\nwith open(anns_file_path, 'r') as f:\n    dataset = json.loads(f.read())\n\ncategories = dataset['categories']\nanns = dataset['annotations']\nimgs = dataset['images']\nnr_cats = len(categories)\nnr_annotations = len(anns)\nnr_images = len(imgs)\n\n# Load categories and super categories\ncat_names = []\nsuper_cat_names = []\nsuper_cat_ids = {}\nsuper_cat_last_name = ''\nnr_super_cats = 0\nfor cat_it in categories:\n    cat_names.append(cat_it['name'])\n    super_cat_name = cat_it['supercategory']\n    # Adding new supercat\n    if super_cat_name != super_cat_last_name:\n        super_cat_names.append(super_cat_name)\n        super_cat_ids[super_cat_name] = nr_super_cats\n        super_cat_last_name = super_cat_name\n        nr_super_cats += 1\n\nprint('Number of super categories:', nr_super_cats)\nprint('Number of categories:', nr_cats)\nprint('Number of annotations:', nr_annotations)\nprint('Number of images:', nr_images)\n\n!pip install pyyaml==5.1\n\nimport torch\nTORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\nCUDA_VERSION = torch.__version__.split(\"+\")[-1]\nprint(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n# Install detectron2 that matches the above pytorch version\n# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n!pip install --ignore-installed detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cpu/torch$TORCH_VERSION/index.html --use-deprecated=html5lib\n#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu10.1/torch$TORCH_VERSION/index.html\n# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n\n#exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime\n\n\n# Some basic setup:\n# Setup detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport numpy as np\nimport os, json, cv2, random\n#from google.colab.patches import cv2_imshow\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\n\nimgs = dataset['images']\nlen_images = len(imgs)\n\ncfg = get_cfg()\ncfg.MODEL.DEVICE = 'cpu'\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\npredictor = DefaultPredictor(cfg)\n#print(\"model config done\")\n\n#for i in range(0,len_images):\nfor i in range(0, 100):\n    #print(imgs[i]['file_name'])\n    im = cv2.imread('data/' + imgs[i]['file_name'])\n    #print(im)\n    outputs = predictor(im)\n    imgs[i]['objects'] = []\n    instances = outputs[\"instances\"]\n    detected_class_indexes = instances.pred_classes\n    prediction_boxes = instances.pred_boxes\n\n    metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n    class_catalog = metadata.thing_classes\n\n    for idx, coordinates in enumerate(prediction_boxes):\n        class_index = detected_class_indexes[idx]\n        class_name = class_catalog[class_index]\n        imgs[i]['objects'].append(class_name)\n\nprint(\"model done\")\n\ndf = pd.DataFrame(imgs)\ndf_train, df_valid = train_test_split(df, test_size = 0.2, shuffle = True)\n\nGARBAGE = 0\nRECYCLING = 1\nCOMPOST = 2\nABSTAIN = -1\n\nfrom snorkel.labeling import labeling_function\n\ngarbage_phrases = [\"plastic\", \"disposable\", \"styrofoam\"]\nrecycling_phrases = [\"paper\", \"carton\", \"can\", \"glass\", \"cardboard\"]\ncompost_phrases = [\"food\"]\n\n# Category-based LFs\n@labeling_function()\ndef lf_garbage_object(x):\n    for obj in x.objects:\n        for phrase in garbage_phrases:\n            if phrase in obj:\n                return GARBAGE\n    return ABSTAIN\n\n\n@labeling_function()\ndef lf_recycling_object(x):\n    for obj in x.objects:\n        for phrase in recycling_phrases:\n            if phrase in obj:\n                return RECYCLING\n    return ABSTAIN\n\n\n@labeling_function()\ndef lf_compost_object(x):\n    for obj in x.objects:\n        for phrase in compost_phrases:\n            if phrase in obj:\n                return COMPOST\n    return ABSTAIN\n\nfrom snorkel.labeling import PandasLFApplier\n\nlfs = [\n    lf_garbage_object,\n    lf_recycling_object,\n    lf_compost_object\n]\n\napplier = PandasLFApplier(lfs)\nL_train = applier.apply(df_train)\nL_valid = applier.apply(df_valid)\n\nfrom snorkel.labeling import LFAnalysis\n\nY_valid = df_valid.label.values\nLFAnalysis(L_valid, lfs).lf_summary(Y_valid)\n\nfrom snorkel.labeling.model import LabelModel\n\nlabel_model = LabelModel(cardinality=3, verbose=True)\nlabel_model.fit(L_train, seed=123, lr=0.01, log_freq=10, n_epochs=100)\n\nprint(L_valid)\n\nlabel_model.score(L_valid, Y_valid, metrics=[\"f1_micro\"])\n\n## Training Classifier\n\n#### Create DataLoaders for Classifier\n\nfrom snorkel.classification import DictDataLoader\nfrom model import SceneGraphDataset, create_model\n\ndf_train[\"labels\"] = label_model.predict(L_train)\n\nif sample:\n    TRAIN_DIR = \"data/VRD/sg_dataset/samples\"\nelse:\n    TRAIN_DIR = \"data/VRD/sg_dataset/sg_train_images\"\n\ndl_train = DictDataLoader(\n    SceneGraphDataset(\"train_dataset\", \"train\", TRAIN_DIR, df_train),\n    batch_size=16,\n    shuffle=True,\n)\n\ndl_valid = DictDataLoader(\n    SceneGraphDataset(\"valid_dataset\", \"valid\", TRAIN_DIR, df_valid),\n    batch_size=16,\n    shuffle=False,\n)\n\n#### Define Model Architecture\n\nimport torchvision.models as models\n\n# initialize pretrained feature extractor\ncnn = models.resnet18(pretrained=True)\nmodel = create_model(cnn)\n\n### Train and Evaluate Model\n\nfrom snorkel.classification import Trainer\n\ntrainer = Trainer(\n    n_epochs=1,  # increase for improved performance\n    lr=1e-3,\n    checkpointing=True,\n    checkpointer_config={\"checkpoint_dir\": \"checkpoint\"},\n)\ntrainer.fit(model, [dl_train])\n\nmodel.score([dl_valid])",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "84b48acd-a31b-4c11-94de-c671397ab27e"
    }
  ]
}